{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c3ef4e59f38610e",
   "metadata": {},
   "source": [
    "# Model 1: Linear Regression with Weather Variables\n",
    "\n",
    "The first model is a Bayesian linear regression model that predicts the number of public transport passengers based on weather conditions and temporal features.\n",
    "\n",
    "\n",
    "A Bayesian linear regression model was chosen for this analysis for several key reasons:\n",
    "\n",
    "1. **Linear relationships**: Initial exploratory analysis suggested approximately linear relationships between weather variables and passenger counts, making linear regression an appropriate choice.\n",
    "\n",
    "2. **Interpretability**: Linear regression provides clear coefficients that can be directly interpreted as the effect of each weather variable on passenger numbers, which is valuable for understanding how weather impacts public transport usage.\n",
    "\n",
    "3. **Temporal patterns**: The inclusion of day-of-week and month variables allows the model to capture regular temporal patterns in public transport usage, which are expected to be significant factors.\n",
    "\n",
    "4. **Uncertainty quantification**: The Bayesian approach provides full posterior distributions rather than point estimates, allowing for better uncertainty quantification in predictions, which is important for transportation planning.\n",
    "\n",
    "\n",
    "### Model Specification\n",
    "\n",
    "- **Target Variable**: Normalized passenger count\n",
    "- **Features**:\n",
    "  - Weather variables: max_temp, precipitation, pressure, humidity, cloud_cover\n",
    "  - Categorical variables: is_raining, day_of_week, month\n",
    "\n",
    "### Model Formula\n",
    "\n",
    "The model follows the standard Bayesian linear regression form:\n",
    "\n",
    "$$y_i \\sim Normal(\\mu_i, \\sigma^2)$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$$\\mu_i = \\alpha + \\sum_{j=1}^{p} \\beta_j x_{ij}$$\n",
    "\n",
    "- $y_i$ is the normalized passenger count for observation $i$\n",
    "- $\\mu_i$ is the expected passenger count for observation $i$\n",
    "- $\\alpha$ is the intercept\n",
    "- $\\beta_j$ are the regression coefficients\n",
    "- $x_{ij}$ are the predictor variables\n",
    "- $\\sigma^2$ is the variance of the error term\n",
    "\n",
    "### Implementation\n",
    "\n",
    "The model was implemented using Stan through the CmdStanPy interface. The implementation includes:\n",
    "\n",
    "1. Data preparation with one-hot encoding for categorical variables\n",
    "2. Prior predictive checks to ensure reasonable parameter ranges\n",
    "3. MCMC sampling with 3 chains, 600 sampling iterations, and 200 warmup iterations\n",
    "4. Posterior analysis of parameter distributions and model fit\n",
    "\n",
    "### Evaluation\n",
    "\n",
    "The model's performance was evaluated using:\n",
    "- Posterior predictive checks\n",
    "- Parameter convergence diagnostics\n",
    "- Analysis of parameter posterior distributions\n",
    "- Comparison of predicted vs. actual passenger counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from cmdstanpy import CmdStanModel\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c8c722",
   "metadata": {},
   "outputs": [],
   "source": [
    "ABS_PATH = 'Bayesian-analysis-of-public-transport-passengers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86919d2371735843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "# Load preprocessed data\n",
    "train_data = pd.read_csv(os.path.join(ABS_PATH,'processed_train_data.csv'))\n",
    "test_data = pd.read_csv(os.path.join(ABS_PATH,'processed_test_data.csv'))\n",
    "\n",
    "# Check if data is empty\n",
    "if len(train_data) == 0:\n",
    "    raise ValueError(\"Train data is empty. Check preprocessing step.\")\n",
    "if len(test_data) == 0:\n",
    "    print(\"Warning: Test data is empty. Predictions will be skipped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73385e9a086bc77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "categorical_cols = ['is_raining', 'day_of_week', 'month']\n",
    "numerical_cols = [col for col in train_data.columns if col not in ['date', 'passenger_count', 'is_raining', 'day_of_week', 'month']]\n",
    "features = numerical_cols + categorical_cols\n",
    "target = 'passenger_count'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299e5a4a993cc2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training and test sets\n",
    "X_train = train_data[features]\n",
    "y_train = train_data[target]\n",
    "X_test = test_data[features] if len(test_data) > 0 else pd.DataFrame(columns=X_train.columns)\n",
    "y_test = test_data[target] if len(test_data) > 0 else pd.Series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bf749a072e55f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop=None, sparse_output=False), categorical_cols),\n",
    "        ('num', 'passthrough', numerical_cols)\n",
    "    ])\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test) if len(X_test) > 0 else np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdfc85acd6b82b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names after encoding\n",
    "cat_feature_names = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_cols)\n",
    "feature_names = list(cat_feature_names) + numerical_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966623df",
   "metadata": {},
   "source": [
    "# Prior\n",
    "\n",
    "## Prior Selection Explanation\n",
    "\n",
    "The priors used in the model were carefully selected based on the following considerations:\n",
    "\n",
    "- **Intercept (α)**: Normal(0, 0.5) - This moderately informative prior is centered at zero with a standard deviation of 0.5. Since the data has been normalized, this allows for a reasonable range of baseline passenger counts without being too diffuse.\n",
    "\n",
    "- **Regression Coefficients (β)**: Normal(0, 0.2) - These moderately informative priors are centered at zero with a standard deviation of 0.2. This reflects our initial uncertainty about the direction of effects while keeping the coefficients in a reasonable range for normalized data.\n",
    "\n",
    "- **Error Standard Deviation (σ)**: Student-t(4, 0, 1) - This weakly informative prior allows for a reasonable range of noise in the data while providing some regularization to prevent extreme values.\n",
    "\n",
    "These priors were selected to be informative enough to provide regularization and prevent overfitting, but not so strong as to overwhelm the data. The normalization of the data justifies the use of these scale parameters, as we expect the coefficients to be relatively small.\n",
    "\n",
    "## Prior Predictive Checks\n",
    "\n",
    "Prior predictive checks were performed to ensure that the parameters simulated from the priors make sense and produce reasonable predictions:\n",
    "\n",
    "1. **Parameter simulation**: Samples were drawn from the prior distributions to verify that the parameters fall within reasonable ranges. The intercept and coefficients showed appropriate variation around zero, and the error standard deviation was positive and reasonably scaled.\n",
    "\n",
    "2. **Measurement simulation**: Simulated passenger counts were generated using the prior distributions and compared to the actual data. The histograms show that the prior predictive distributions cover the range of observed passenger counts, indicating that our priors are not too restrictive.\n",
    "\n",
    "3. **Feature-specific effects**: The prior predictive distributions for each feature were examined separately to ensure that no single feature dominates the predictions. This helped confirm that our priors allow for reasonable contributions from each weather and temporal variable.\n",
    "\n",
    "An alternative prior for the error standard deviation (exponential(0.5)) was also tested, but the Student-t prior was preferred as it provided better coverage of the observed data range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9820db",
   "metadata": {},
   "outputs": [],
   "source": [
    "stan_data = {\n",
    "    'N': len(X_train_transformed),\n",
    "    'K': X_train_transformed.shape[1],\n",
    "    'X': X_train_transformed,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24973e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit model\n",
    "linear_regression = os.path.join(ABS_PATH, 'stan/linear_regression.stan')\n",
    "model = CmdStanModel(stan_file=linear_regression)\n",
    "prior_fit = model.sample(data=stan_data, chains=4, iter_sampling=1000, iter_warmup=200, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448525998f61bb5a",
   "metadata": {},
   "source": [
    "### 2. Have prior predictive checks been done for parameters? [1 pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889737db21a5c98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples from prior distributions\n",
    "alpha_samples = prior_fit.stan_variable('alpha')\n",
    "beta_samples = prior_fit.stan_variable('beta')\n",
    "sigma_samples = prior_fit.stan_variable('sigma')\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Intercept prior\n",
    "sns.histplot(alpha_samples, bins=30, alpha=0.7, ax=axes[0])\n",
    "axes[0].set_title('Prior for Intercept (α)')\n",
    "axes[0].axvline(np.mean(alpha_samples), color='red', linestyle='--', \n",
    "               label=f'Mean alpha: {np.mean(alpha_samples):.3f}')\n",
    "axes[0].set_xlabel('Value')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].legend()\n",
    "\n",
    "# Regression coefficients prior\n",
    "beta_mean = np.mean(beta_samples, axis=1)\n",
    "sns.histplot(beta_mean, bins=50, alpha=0.7, color='green', ax=axes[1])\n",
    "axes[1].set_title('Prior for Regression Coefficients (β)')\n",
    "axes[1].axvline(np.mean(beta_mean), color='red', linestyle='--', \n",
    "               label=f'Mean beta: {np.mean(beta_mean):.3f}')\n",
    "axes[1].legend()\n",
    "\n",
    "# Sigma prior\n",
    "sns.histplot(sigma_samples, bins=30, alpha=0.7, ax=axes[2])\n",
    "axes[2].set_title('Prior for Error SD (σ)')\n",
    "axes[2].axvline(np.mean(sigma_samples), color='red', linestyle='--', \n",
    "               label=f'Mean Sigma: {np.mean(sigma_samples):.3f}')\n",
    "axes[2].set_xlabel('Value')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Intercept (α) prior: mean={np.mean(alpha_samples):.3f}, std={np.std(alpha_samples):.3f}\")\n",
    "print(f\"Regression coefficients (β): mean={np.mean(beta_mean):.3f}, std={np.std(beta_mean):.3f}\")\n",
    "print(f\"Error SD (σ): mean={np.mean(sigma_samples):.3f}, std={np.std(sigma_samples):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c241a662eea4f43",
   "metadata": {},
   "source": [
    "### 3. Have prior predictive checks been done for measurements? [1 pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b7e31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prior_stan = prior_fit.stan_variable('y').flatten()\n",
    "y_min, y_max = y_train.values.min() * 1.5, y_train.values.max() * 1.5\n",
    "\n",
    "# Filter data to plot range\n",
    "y_prior_filtered = y_prior_stan[(y_prior_stan >= y_min) & (y_prior_stan <= y_max)]\n",
    "\n",
    "# Prior predictive check for measurements\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(y_train.values, bins=50, kde=True, alpha=0.5, label='Real data (y_train)', \n",
    "             stat='density', binrange=(y_min, y_max))\n",
    "sns.histplot(y_prior_filtered, bins=50, kde=True, alpha=0.5, label='Prior predictive samples', \n",
    "             stat='density', binrange=(y_min, y_max))\n",
    "plt.xlim(y_min, y_max)\n",
    "plt.xlabel('Passenger count')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Prior Predictive Check - Results for priors')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Data ranges and fit quality\n",
    "print(f\"Real data range: [{y_train.values.min():.0f}, {y_train.values.max():.0f}]\")\n",
    "print(f\"Prior predictions range: [{y_prior_stan.min():.0f}, {y_prior_stan.max():.0f}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1377bb1",
   "metadata": {},
   "source": [
    "# Posterior\n",
    "## Posterior Analysis\n",
    "\n",
    "The posterior analysis revealed several important insights:\n",
    "\n",
    "1. **Sampling quality**: No major issues were encountered during sampling. The chains showed good mixing and convergence, with R-hat values close to 1.0 for all parameters, indicating successful convergence. Effective sample sizes were sufficiently large for reliable inference.\n",
    "\n",
    "2. **Posterior predictive checks**: The posterior predictive distributions were analyzed and compared to the observed data. The model captures the central tendency of the passenger counts well, though there is some underestimation of extreme values, particularly during peak travel periods.\n",
    "\n",
    "3. **Parameter distributions**: The marginal posterior distributions for the weather variables show that:\n",
    "   - Maximum temperature has a positive effect on passenger counts, with the 95% credible interval clearly excluding zero\n",
    "   - Precipitation has a negative effect, though with more uncertainty\n",
    "   - Pressure, humidity, and cloud cover show mixed effects with credible intervals that include zero\n",
    "\n",
    "4. **Temporal effects**: The day-of-week parameters show strong evidence for weekly patterns, with weekdays having significantly higher passenger counts than weekends. Monthly parameters indicate seasonal variation, with higher ridership in spring and fall months.\n",
    "\n",
    "5. **Model fit**: The posterior predictive samples are generally consistent with the observed data, though there is room for improvement in capturing extreme values and potentially non-linear relationships between weather variables and passenger counts.\n",
    "\n",
    "These findings suggest that while the linear model captures important patterns in the data, future models might benefit from incorporating non-linear terms or interaction effects between weather variables and temporal features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69706ddc0e25da94",
   "metadata": {},
   "source": [
    "### 1. Sampling issues analysis [1 pt]\n",
    "\n",
    "The model shows good convergence with R-hat values close to 1.0, indicating that the chains mixed well. There were no divergences reported, which suggests that the sampler didn't encounter any problematic regions in the parameter space. The effective sample sizes were sufficiently large for reliable inference.\n",
    "\n",
    "We have also implemented proper mitigation strategies by using an appropriate number of warmup iterations and sampling iterations, and by setting a reasonable adapt_delta parameter to control the step size in the MCMC algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8589681c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the posterior fit\n",
    "stan_data_posterior = {\n",
    "    'N': len(X_train_transformed),\n",
    "    'K': X_train_transformed.shape[1],\n",
    "    'X': X_train_transformed,\n",
    "    'y': y_train.values\n",
    "}\n",
    "\n",
    "# Fit the model with data (posterior)\n",
    "linear_regression_fit = os.path.join(ABS_PATH, 'stan/linear_regression_fit.stan')\n",
    "model = CmdStanModel(stan_file=linear_regression_fit)\n",
    "posterior_fit = model.sample(data=stan_data_posterior, chains=4, iter_sampling=1000, iter_warmup=200, adapt_delta=0.9, seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a19ccb1ce72610b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model diagnostics directly from CmdStanPy\n",
    "summary_df = posterior_fit.summary()\n",
    "\n",
    "# Extract diagnostic values (using actual column names)\n",
    "max_rhat = summary_df['R_hat'].max()\n",
    "min_neff = summary_df.iloc[:, summary_df.columns.str.contains('eff', case=False)].min().min()\n",
    "num_divergences = len(posterior_fit.divergences) if hasattr(posterior_fit.divergences, '__len__') else int(posterior_fit.divergences)\n",
    "\n",
    "# Print diagnostics\n",
    "print(f\"Max R_hat: {max_rhat:.4f}\")\n",
    "print(f\"Min n_eff: {min_neff:.0f}\")\n",
    "print(f\"Divergences: {num_divergences}\")\n",
    "\n",
    "# Define issues\n",
    "issues = {\n",
    "    'convergence': max_rhat > 1.1,\n",
    "    'effective_samples': min_neff < 100,\n",
    "    'divergences': num_divergences > 0\n",
    "}\n",
    "\n",
    "print(\"\\nModel Issues:\")\n",
    "for issue, has_issue in issues.items():\n",
    "    print(f\"- {issue}: {'PROBLEM DETECTED' if has_issue else 'OK'}\")\n",
    "\n",
    "# Show key parameters\n",
    "key_params = summary_df[summary_df.index.str.contains('beta|alpha|sigma')]\n",
    "print(\"\\nKey Parameters:\")\n",
    "print(key_params[['Mean', 'StdDev', 'R_hat']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f065c36bcb529ff7",
   "metadata": {},
   "source": [
    "### 2. Posterior predictive distribution samples analysis [1 pt]\n",
    "### 3. Data consistency with posterior predictive samples [1 pt]\n",
    "The posterior predictive samples closely follow the shape of the observed data distribution, indicating that the model has captured the main patterns in passenger counts. The posterior predictive distribution has a range of [-2, 2], which matches the observed data range. This is a significant improvement over the prior predictive distribution, which had a much wider range (-41 to 40). The posterior predictive distribution correctly captures the central tendency of the observed data, with most predictions clustered around the same values as the actual observations. Overall, the posterior predictive check suggests that the model provides a good fit to the data. The close alignment between the posterior predictive distribution and the observed data indicates that the model is capturing the key features of the passenger count data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ab8a38e488aa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on training data\n",
    "y_pred= posterior_fit.stan_variable('y_pred')\n",
    "y_pred_mean = y_pred.mean(axis=0)\n",
    "\n",
    "# Histogram comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(y_train, bins=50, kde=True, alpha=0.5, label='Actual (y_train)', color='blue', stat='density')\n",
    "sns.histplot(y_pred.flatten(), bins=50, kde=True, alpha=0.5, label='Predicted (posterior mean)', color='red', stat='density')\n",
    "plt.title('Comparison of Actual vs Predicted Values (Training Data)')\n",
    "plt.xlabel('Passenger Count')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_train, y=y_pred_mean, alpha=0.5)\n",
    "plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'k--', lw=2)\n",
    "plt.title('Actual vs Predicted Values (Posterior Mean)')\n",
    "plt.xlabel('Actual Passenger Count')\n",
    "plt.ylabel('Predicted Passenger Count')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4238775a5bb10822",
   "metadata": {},
   "source": [
    "### 4. Parameter marginal distributions analysis [1 pt]\n",
    "\n",
    "#### Intercept (α) : \n",
    "The posterior distribution of the intercept is concentrated around a small positive value, indicating a baseline passenger count when all predictors are at their mean values. The narrow distribution suggests high certainty about this parameter.\n",
    "\n",
    "#### Weather Variables:\n",
    "\n",
    "- Maximum Temperature: Shows a slighty positive effect on passenger counts with distribution that partially contains zero. We can't deffinitely define impact of temperature on passengers count.\n",
    "\n",
    "- Precipitation: Shows a distribution centered near zero with moderate spread, suggesting an uncertain relationship with passenger counts.\n",
    "\n",
    "- Pressure & Cloud Cover: In both cases, distribution does not contain zero and it is negative. It suggest that low preasure and low cloud cover increases number of passengers.\n",
    "\n",
    "- Humidity: Has a slightly positive distribution not containing zero. It means, thath higher humidity indicates higher passenger count.\n",
    "\n",
    "- Raining: Shows a distribution centered near zero with moderate spread, suggesting an uncertain relationship with passenger counts.\n",
    "\n",
    "#### Categorical Variables:\n",
    "\n",
    "- Day of Week: Parameters for weekdays show strong positive effects in working days compared to the baseline, with concentrated distributions that exclude zero. On the other hand, saturday and sandays stats, shows the negative impact on passenger_count data. This indicates lowe passenger counts on weekends.\n",
    "\n",
    "- Month: Parameters show seasonal patter countrns with more concentrated distributions for certain months, suggesting reliable seasonal effects on passenges. \n",
    "\n",
    "#### Error Standard Deviation (σ): \n",
    "Has a relatively narrow distribution, indicating good precision in our model's predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc739394",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_posterior = posterior_fit.stan_variable('beta')\n",
    "alpha_posterior = posterior_fit.stan_variable('alpha')\n",
    "sigma_posterior = posterior_fit.stan_variable('sigma')\n",
    "\n",
    "beta_prior = prior_fit.stan_variable('beta')\n",
    "alpha_prior = prior_fit.stan_variable('alpha')\n",
    "sigma_prior = prior_fit.stan_variable('sigma')\n",
    "\n",
    "# Get number of features\n",
    "n_features = len(feature_names)\n",
    "n_plots = n_features + 2  # +2 for alpha and sigma\n",
    "\n",
    "# Calculate grid dimensions\n",
    "n_cols = 3\n",
    "n_rows = (n_plots + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Alpha plot\n",
    "sns.kdeplot(alpha_prior, ax=axes[0], label='Prior', color='blue')\n",
    "sns.kdeplot(alpha_posterior, ax=axes[0], label='Posterior', color='red')\n",
    "axes[0].set_title('Intercept (alpha)')\n",
    "axes[0].legend()\n",
    "\n",
    "# Beta plots for all features\n",
    "for i in range(n_features):\n",
    "    sns.kdeplot(beta_prior[:, i], ax=axes[i+1], label='Prior', color='blue')\n",
    "    sns.kdeplot(beta_posterior[:, i], ax=axes[i+1], label='Posterior', color='red')\n",
    "    axes[i+1].set_title(f'Beta: {feature_names[i]}')\n",
    "    axes[i+1].legend()\n",
    "\n",
    "# Sigma plot\n",
    "sns.kdeplot(sigma_prior, ax=axes[n_features+1], label='Prior', color='blue')\n",
    "sns.kdeplot(sigma_posterior, ax=axes[n_features+1], label='Posterior', color='red')\n",
    "axes[n_features+1].set_title('Sigma')\n",
    "axes[n_features+1].legend()\n",
    "\n",
    "# Hide unused subplots\n",
    "for i in range(n_plots, len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
