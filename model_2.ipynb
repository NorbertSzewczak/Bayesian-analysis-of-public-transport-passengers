{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from cmdstanpy import CmdStanModel\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import arviz as az"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load preprocessed data\n",
    "train_data = pd.read_csv('processed_train_data.csv')\n",
    "test_data = pd.read_csv('processed_test_data.csv')\n",
    "\n",
    "# Check if data is empty\n",
    "if len(train_data) == 0:\n",
    "    raise ValueError(\"Train data is empty. Check preprocessing step.\")\n",
    "if len(test_data) == 0:\n",
    "    print(\"Warning: Test data is empty. Predictions will be skipped.\")"
   ],
   "id": "289afb971c8498b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## Define features (exclude quality flags and season)\n",
    "categorical_cols = ['is_raining', 'day_of_week', 'month']\n",
    "# Corrected column name based on actual data\n",
    "numerical_cols = ['max_temp',\n",
    "                  'precipitation', 'pressure',\n",
    "                  'humidity', 'cloud_cover']\n",
    "features = numerical_cols + categorical_cols\n",
    "target = 'passenger_count'"
   ],
   "id": "a3f6e13f5d79a054"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Prepare training and test sets\n",
    "X_train = train_data[features]\n",
    "y_train = train_data[target]\n",
    "X_test = test_data[features] if len(test_data) > 0 else pd.DataFrame(columns=X_train.columns)\n",
    "y_test = test_data[target] if len(test_data) > 0 else pd.Series()"
   ],
   "id": "224ed1a100e306ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Preprocess categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_cols),\n",
    "        ('num', 'passthrough', numerical_cols)\n",
    "    ])\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test) if len(X_test) > 0 else np.array([])\n",
    "\n",
    "# Get feature names\n",
    "cat_feature_names = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_cols)\n",
    "feature_names = list(cat_feature_names) + numerical_cols\n",
    "dow_indices = [i for i, name in enumerate(feature_names) if name.startswith('day_of_week_')]"
   ],
   "id": "388beeaf46bf4039"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Prior",
   "id": "498e304698a912a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Update stan_data to include the number of day_of_week indices\n",
    "stan_data = {\n",
    "    'N': len(X_train_transformed),\n",
    "    'K': X_train_transformed.shape[1],\n",
    "    'X': X_train_transformed,\n",
    "    'num_dow_indices': len(dow_indices),  # Add the size of the dow_indices array\n",
    "    'dow_indices': [i+1 for i, name in enumerate(feature_names) if name.startswith('day_of_week_')]  # 1-based indexing for Stan\n",
    "}"
   ],
   "id": "686b6d8098b9d7cc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Update the Stan code to declare dow_indices with the correct size\n",
    "priors_stan = \"\"\"\n",
    "data {\n",
    "  int<lower=0> N;          // Number of samples to generate\n",
    "  int<lower=0> K;          // Number of features\n",
    "  matrix[N, K] X;          // Feature matrix\n",
    "  int<lower=0> num_dow_indices; // Number of day_of_week features\n",
    "  array[num_dow_indices] int<lower=1, upper=K> dow_indices;  // Indices of day_of_week features\n",
    "}\n",
    "parameters {\n",
    "  real beta0;              // Intercept\n",
    "  vector[K] beta;          // Feature coefficients\n",
    "  real mu_dow;             // Mean of day_of_week coefficients\n",
    "  real<lower=0> sigma_dow; // SD of day_of_week coefficients\n",
    "  real<lower=0> sigma;     // Noise standard deviation\n",
    "}\n",
    "model {\n",
    "  // Priors\n",
    "  beta0 ~ normal(0, 0.9);\n",
    "  for (k in 1:K) {\n",
    "    // Check if the current index k is one of the dow_indices\n",
    "    int is_dow = 0; // Flag to indicate if k is a dow index\n",
    "    for (i in 1:size(dow_indices)) { // Iterate through dow_indices\n",
    "      if (k == dow_indices[i]) {\n",
    "        is_dow = 1; // Set flag if match found\n",
    "      }\n",
    "    }\n",
    "\n",
    "    if (is_dow == 1) { // Use the flag in the conditional\n",
    "      beta[k] ~ normal(mu_dow, sigma_dow);\n",
    "    } else {\n",
    "      beta[k] ~ normal(0, 1);\n",
    "    }\n",
    "  }\n",
    "  mu_dow ~ normal(0, 0.3);\n",
    "  sigma_dow ~ normal(0, 0.3);\n",
    "  sigma ~ normal(0, 0.3);\n",
    "}\n",
    "generated quantities {\n",
    "  vector[N] y;             // Generated target variable\n",
    "  array[K] vector[N] y_per_feature;  // Per-feature prior predictive\n",
    "  for (n in 1:N) {\n",
    "    y[n] = normal_rng(X[n] * beta + beta0, sigma);\n",
    "    for (k in 1:K) {\n",
    "      y_per_feature[k, n] = normal_rng(X[n, k] * beta[k] + beta0, sigma);\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "# Save Stan model\n",
    "with open('hierarchical_regression_priors.stan', 'w') as f:\n",
    "    f.write(priors_stan)"
   ],
   "id": "86d12473417e701c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = CmdStanModel(stan_file='hierarchical_regression_priors.stan')\n",
    "fit = model.sample(data=stan_data, chains=4, iter_sampling=2000, iter_warmup=500, adapt_delta=0.9 ,seed=42)"
   ],
   "id": "3e5c33c6cc9ad70c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Extract prior predictive samples\n",
    "y_prior = fit.stan_variable('y').flatten()  # Shape: (n_samples * N,)\n",
    "y_per_feature = fit.stan_variable('y_per_feature')  # Shape: (n_samples, K, N)\n",
    "real_data = y_train.values\n",
    "\n",
    "# Visualization: Histograms for real and prior predictive passenger_count for each feature\n",
    "n_features = len(feature_names)\n",
    "fig, axes = plt.subplots(nrows=(n_features + 2) // 3, ncols=min(n_features, 3), figsize=(15, 5 * ((n_features + 2) // 3)))\n",
    "axes = axes.flatten() if n_features > 1 else [axes]\n",
    "bin_range = (real_data.min() * 1.5, real_data.max() * 1.5)\n",
    "# Plot for each feature\n",
    "for idx, feature in enumerate(feature_names):\n",
    "    # Extract prior predictive samples for this feature (flatten across samples and observations)\n",
    "    y_feature = y_per_feature[:, idx, :].flatten()  # Shape: (n_samples * N,)\n",
    "\n",
    "    # Plot histograms with plt.hist\n",
    "    axes[idx].hist(real_data, bins=20, density=True, alpha=0.5, label='Real passenger_count', color='blue',\n",
    "                   range=bin_range, histtype='stepfilled')\n",
    "    axes[idx].hist(y_feature, bins=20, density=True, alpha=0.5, label=f'Prior Predictive ({feature})', color='orange',\n",
    "                   range=bin_range, histtype='stepfilled')\n",
    "\n",
    "    axes[idx].set_title(f'Effect of {feature} on passenger_count')\n",
    "    axes[idx].set_xlabel('passenger_count')\n",
    "    axes[idx].set_ylabel('Density')\n",
    "    axes[idx].legend()\n",
    "\n",
    "# Adjust layout and display\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "fea7fa98b7c0e0de"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Posterior",
   "id": "b312ec2cd77ed87c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define data\n",
    "stan_data = {\n",
    "    'N': len(X_train_transformed),\n",
    "    'K': X_train_transformed.shape[1],\n",
    "    'X': X_train_transformed,\n",
    "    'y': y_train.values,\n",
    "    'dow_indices': [i+1 for i, name in enumerate(feature_names) if name.startswith('day_of_week_')],\n",
    "    'num_dow_indices': len([i+1 for i, name in enumerate(feature_names) if name.startswith('day_of_week_')]) # Add num_dow_indices here\n",
    "}"
   ],
   "id": "f674d6b47171b002"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define Stan model with log-likelihood for arviz\n",
    "stan_code = \"\"\"\n",
    "data {\n",
    "  int<lower=0> N;          // Number of training samples\n",
    "  int<lower=0> K;          // Number of features\n",
    "  matrix[N, K] X;          // Feature matrix\n",
    "  vector[N] y;             // Target variable\n",
    "  int<lower=0> num_dow_indices; // Number of day_of_week features (Added for loop)\n",
    "  array[num_dow_indices] int<lower=1, upper=K> dow_indices;  // Indices of day_of_week features\n",
    "}\n",
    "parameters {\n",
    "  real beta0;              // Intercept\n",
    "  vector[K] beta;          // Feature coefficients\n",
    "  real mu_dow;             // Mean of day_of_week coefficients\n",
    "  real<lower=0> sigma_dow; // SD of day_of_week coefficients\n",
    "  real<lower=0> sigma;     // Noise standard deviation\n",
    "}\n",
    "model {\n",
    "  vector[N] mu;\n",
    "  // Priors\n",
    "  beta0 ~ normal(0, 0.9);\n",
    "  for (k in 1:K) {\n",
    "    // Check if the current index k is one of the dow_indices\n",
    "    int is_dow = 0; // Flag to indicate if k is a dow index\n",
    "    for (i in 1:num_dow_indices) { // Iterate through dow_indices\n",
    "      if (k == dow_indices[i]) {\n",
    "        is_dow = 1; // Set flag if match found\n",
    "        break; // Exit the inner loop once a match is found\n",
    "      }\n",
    "    }\n",
    "\n",
    "    if (is_dow == 1) {\n",
    "      beta[k] ~ normal(mu_dow, sigma_dow);\n",
    "    } else {\n",
    "      beta[k] ~ normal(0, 1);\n",
    "    }\n",
    "  }\n",
    "  mu_dow ~ normal(0, 0.3);\n",
    "  sigma_dow ~ normal(0, 0.3);\n",
    "  sigma ~ normal(0, 0.3);\n",
    "\n",
    "  // Likelihood\n",
    "  for (n in 1:N) {\n",
    "    mu[n] = beta0 + dot_product(X[n], beta);\n",
    "  }\n",
    "  y ~ normal(mu, sigma);\n",
    "}\n",
    "generated quantities {\n",
    "  vector[N] y_pred;        // Posterior predictive checks\n",
    "  vector[N] log_lik;       // Log likelihood for model evaluation\n",
    "  array[K] vector[N] y_per_feature;  // Per-feature posterior predictive\n",
    "  for (n in 1:N) {\n",
    "    y_pred[n] = normal_rng(X[n] * beta + beta0, sigma);\n",
    "    log_lik[n] = normal_lpdf(y[n] | X[n] * beta + beta0, sigma);\n",
    "    for (k in 1:K) {\n",
    "      y_per_feature[k, n] = normal_rng(X[n, k] * beta[k] + beta0, sigma);\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Save Stan model\n",
    "with open('hierarchical_regression_poterior.stan', 'w') as f:\n",
    "    f.write(stan_code)"
   ],
   "id": "20313f08514f50e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Compile and fit model\n",
    "model = CmdStanModel(stan_file='hierarchical_regression_poterior.stan')\n",
    "posterior_fit = model.sample(data=stan_data, chains=4, iter_sampling=600, iter_warmup=300, adapt_delta=0.90 ,seed=42)"
   ],
   "id": "a67b9c3825b043fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Convert to arviz InferenceData for posterior analysis\n",
    "idata = az.from_cmdstanpy(posterior=posterior_fit, log_likelihood='log_lik')\n",
    "\n",
    "# Extract posterior predictive samples\n",
    "y_pred = fit.stan_variable('y').mean(axis=0)  # Mean posterior predictive\n",
    "y_per_feature = fit.stan_variable('y_per_feature')  # Posterior predictive per feature\n",
    "\n",
    "# Visualization: Histograms for real data vs posterior predictive for each feature\n",
    "n_features = len(feature_names)\n",
    "fig, axes = plt.subplots(nrows=(n_features + 2) // 3, ncols=min(n_features, 3), figsize=(15, 5 * ((n_features + 2) // 3)))\n",
    "axes = axes.flatten() if n_features > 1 else [axes]\n",
    "bin_range = (real_data.min() * 1.5, real_data.max() * 1.5)\n",
    "real_data = y_train.values\n",
    "for idx, feature in enumerate(feature_names):\n",
    "    y_feature = y_per_feature[:, idx, :].mean(axis=0)  # Mean posterior predictive per feature\n",
    "    axes[idx].hist(real_data, bins=50, density=True, alpha=0.5, label='Real passenger_count', color='blue', range=bin_range, histtype='stepfilled')\n",
    "    axes[idx].hist(y_feature, bins=50, density=True, alpha=0.5, label=f'Posterior Predictive ({feature})', color='green', range=bin_range, histtype='stepfilled')\n",
    "    axes[idx].set_title(f'Effect of {feature} on passenger_count')\n",
    "    axes[idx].set_xlabel('passenger_count')\n",
    "    axes[idx].set_ylabel('Density')\n",
    "    axes[idx].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "a430fdb5e4858567"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Check sampling diagnostics\n",
    "summary = fit.summary()\n",
    "rhat = summary['R_hat'].max() if 'R_hat' in summary.columns else float('nan')\n",
    "# Try 'n_eff' as the column name, fallback to None if missing\n",
    "n_eff = summary['n_eff'].min() if 'n_eff' in summary.columns else None\n",
    "print(f\"Sampling Diagnostics: Max R-hat = {rhat:.4f}, Min N_Eff = {n_eff if n_eff is not None else 'N/A'}\")\n",
    "if rhat > 1.1 or (n_eff is not None and n_eff < 100):\n",
    "    print(\"Warning: Sampling issues detected. Consider increasing iter_sampling or adapt_delta, or check model specification.\")"
   ],
   "id": "7b9ac31831433227"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Posterior predictive analysis\n",
    "if len(X_test_transformed) > 0:\n",
    "    y_pred = fit.stan_variable('y_pred').mean(axis=0)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"Posterior Predictive Metrics (Model 2):\")\n",
    "    print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "    print(f\"RÂ² Score: {r2:.4f}\")\n",
    "    # Check consistency\n",
    "    y_pred_samples = fit.stan_variable('y_pred')\n",
    "    credible_intervals = np.percentile(y_pred_samples, [2.5, 97.5], axis=0)\n",
    "    within_ci = np.mean((y_test >= credible_intervals[0]) & (y_test <= credible_intervals[1]))\n",
    "    print(f\"Proportion of test data within 95% credible intervals: {within_ci:.2f}\")\n",
    "    if within_ci < 0.9:\n",
    "        print(\"Warning: Less than 90% of test data within credible intervals. Consider non-linear effects or additional features.\")"
   ],
   "id": "7b707bd6ac6ed27a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Visualization: Actual vs. Predicted Passenger Counts\n",
    "    if 'date' in test_data.columns:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(test_data['date'], y_test, label='Actual', color='blue')\n",
    "        plt.plot(test_data['date'], y_pred, label='Predicted', color='red', alpha=0.7)\n",
    "        plt.title('Actual vs. Predicted Passenger Counts (Model 2)')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Normalized Passenger Count')\n",
    "        plt.legend()\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('actual_vs_predicted_model2.png')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(y_test.index, y_test, label='Actual', color='blue')\n",
    "        plt.plot(y_test.index, y_pred, label='Predicted', color='red', alpha=0.7)\n",
    "        plt.title('Actual vs. Predicted Passenger Counts (Model 2)')\n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel('Normalized Passenger Count')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('actual_vs_predicted_model2.png')\n",
    "        plt.close()\n",
    "\n",
    "    # Visualization: Residuals Plot\n",
    "    residuals = y_test - y_pred\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.scatter(test_data['date'] if 'date' in test_data.columns else y_test.index, residuals, color='purple', alpha=0.5)\n",
    "    plt.axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "    plt.title('Residuals of Predicted vs. Actual Passenger Counts (Model 2)')\n",
    "    plt.xlabel('Date' if 'date' in test_data.columns else 'Index')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('residuals_model2.png')\n",
    "    plt.close()"
   ],
   "id": "3f9cd9e453bff8d4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Parameter marginal distributions\n",
    "beta_samples = fit.stan_variable('beta')\n",
    "beta0_samples = fit.stan_variable('beta0')\n",
    "sigma_samples = fit.stan_variable('sigma')\n",
    "mu_dow_samples = fit.stan_variable('mu_dow')\n",
    "sigma_dow_samples = fit.stan_variable('sigma_dow')\n",
    "print(\"\\nParameter Summaries (Model 2):\")\n",
    "for i, name in enumerate(feature_names):\n",
    "    mean, std = beta_samples[:, i].mean(), beta_samples[:, i].std()\n",
    "    ci = np.percentile(beta_samples[:, i], [2.5, 97.5])\n",
    "    print(f\"{name}: Mean = {mean:.4f}, SD = {std:.4f}, 95% CI = [{ci[0]:.4f}, {ci[1]:.4f}]\")\n",
    "print(f\"beta0: Mean = {beta0_samples.mean():.4f}, SD = {beta0_samples.std():.4f}, 95% CI = [{np.percentile(beta0_samples, 2.5):.4f}, {np.percentile(beta0_samples, 97.5):.4f}]\")\n",
    "print(f\"mu_dow: Mean = {mu_dow_samples.mean():.4f}, SD = {mu_dow_samples.std():.4f}, 95% CI = [{np.percentile(mu_dow_samples, 2.5):.4f}, {np.percentile(mu_dow_samples, 97.5):.4f}]\")\n",
    "print(f\"sigma_dow: Mean = {sigma_dow_samples.mean():.4f}, SD = {sigma_dow_samples.std():.4f}, 95% CI = [{np.percentile(sigma_dow_samples, 2.5):.4f}, {np.percentile(sigma_dow_samples, 97.5):.4f}]\")\n",
    "print(f\"sigma: Mean = {sigma_samples.mean():.4f}, SD = {sigma_samples.std():.4f}, 95% CI = [{np.percentile(sigma_samples, 2.5):.4f}, {np.percentile(sigma_samples, 97.5):.4f}]\")"
   ],
   "id": "a0685da39d08028a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Plot parameter histograms\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, name in enumerate(feature_names[:4]):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.hist(beta_samples[:, i], bins=30, density=True)\n",
    "    plt.title(f'Posterior: {name} (Model 2)')\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Density')\n",
    "plt.tight_layout()\n",
    "plt.savefig('parameter_histograms_model2.png')\n",
    "plt.show()"
   ],
   "id": "b185f1062a505f52"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Save sampling output to CSV files\n",
    "csv_dir = \"csv_output_model2\"\n",
    "fit.save_csvfiles(dir=csv_dir)"
   ],
   "id": "f7768424841813fc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Compute information criteria with arviz using from_cmdstanpy\n",
    "idata = az.from_cmdstanpy(posterior=fit, log_likelihood='log_lik')\n",
    "waic = az.waic(idata)\n",
    "loo = az.loo(idata)\n",
    "print(f\"\\nInformation Criteria (Model 2):\")\n",
    "print(f\"WAIC: {waic.elpd_waic} (+/- {waic.se})\")\n",
    "print(f\"PSIS-LOO: {loo.elpd_loo} (+/- {loo.se})\")\n",
    "if any(loo.pareto_k > 0.7):\n",
    "    print(\"Warning: High Pareto k values detected. Results may be unreliable.\")"
   ],
   "id": "72d133e178c0673f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
