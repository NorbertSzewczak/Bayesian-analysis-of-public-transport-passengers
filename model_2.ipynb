{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from cmdstanpy import CmdStanModel\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import arviz as az"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load preprocessed data\n",
    "train_data = pd.read_csv('processed_train_data.csv')\n",
    "test_data = pd.read_csv('processed_test_data.csv')\n",
    "\n",
    "# Check if data is empty\n",
    "if len(train_data) == 0:\n",
    "    raise ValueError(\"Train data is empty. Check preprocessing step.\")\n",
    "if len(test_data) == 0:\n",
    "    print(\"Warning: Test data is empty. Predictions will be skipped.\")\n",
    "\n",
    "# Add this line to print the column names\n",
    "print(train_data.columns)"
   ],
   "id": "289afb971c8498b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define features (exclude quality flags and season)\n",
    "categorical_cols = ['is_raining', 'day_of_week', 'month']\n",
    "# Corrected column name based on actual data\n",
    "numerical_cols = ['passenger_count_lag1', 'temp_7d_mean', 'max_temp', 'Q_TG',\n",
    "                  'precipitation', 'snow_depth', 'global_radiation', 'pressure',\n",
    "                  'humidity', 'cloud_cover']\n",
    "features = numerical_cols + categorical_cols\n",
    "target = 'passenger_count'\n",
    "\n",
    "# Prepare training and test sets\n",
    "X_train = train_data[features]\n",
    "y_train = train_data[target]\n",
    "X_test = test_data[features] if len(test_data) > 0 else pd.DataFrame(columns=X_train.columns)\n",
    "y_test = test_data[target] if len(test_data) > 0 else pd.Series()"
   ],
   "id": "a3f6e13f5d79a054"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Preprocess categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_cols),\n",
    "        ('num', 'passthrough', numerical_cols)\n",
    "    ])\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test) if len(X_test) > 0 else np.array([])\n",
    "\n",
    "# Get feature names\n",
    "cat_feature_names = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_cols)\n",
    "feature_names = list(cat_feature_names) + numerical_cols\n",
    "dow_indices = [i for i, name in enumerate(feature_names) if name.startswith('day_of_week_')]"
   ],
   "id": "388beeaf46bf4039"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Prior predictive checks\n",
    "n_sim = 1000\n",
    "beta0_sim = np.random.normal(0, 5, n_sim)\n",
    "beta_sim = np.random.normal(0, 5, (n_sim, len(feature_names)))\n",
    "mu_dow_sim = np.random.normal(0, 2, n_sim)\n",
    "sigma_dow_sim = np.abs(np.random.standard_cauchy(n_sim))\n",
    "beta_dow_sim = np.array([np.random.normal(mu_dow_sim, sigma_dow_sim) for _ in range(len(dow_indices))]).T\n",
    "sigma_sim = np.abs(np.random.standard_cauchy(n_sim) * 2.5)\n",
    "print(\"Prior Parameter Checks:\")\n",
    "print(f\"beta0 range: [{beta0_sim.min():.2f}, {beta0_sim.max():.2f}]\")\n",
    "print(f\"beta range: [{beta_sim.min():.2f}, {beta_sim.max():.2f}]\")\n",
    "print(f\"mu_dow range: [{mu_dow_sim.min():.2f}, {mu_dow_sim.max():.2f}]\")\n",
    "print(f\"sigma_dow range: [{sigma_dow_sim.min():.2f}, {sigma_dow_sim.max():.2f}]\")\n",
    "print(f\"beta_dow range: [{beta_dow_sim.min():.2f}, {beta_dow_sim.max():.2f}]\")\n",
    "print(f\"sigma range: [{sigma_sim.min():.2f}, {sigma_sim.max():.2f}]\")"
   ],
   "id": "73441a1b4f1dfe36"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Prior predictive measurements\n",
    "if len(X_train_transformed) > 0:\n",
    "    mu_sim = beta0_sim + X_train_transformed[:n_sim] @ beta_sim.T\n",
    "    y_sim = np.array([np.random.normal(mu_sim[i], sigma_sim[i]) for i in range(n_sim)])\n",
    "    print(f\"Prior Predictive Measurements range: [{y_sim.min():.2f}, {y_sim.max():.2f}]\")\n",
    "    plt.hist(y_sim.flatten(), bins=50, density=True)\n",
    "    plt.title('Prior Predictive Distribution of Passenger Counts (Model 2)')\n",
    "    plt.xlabel('Normalized Passenger Count')\n",
    "    plt.ylabel('Density')\n",
    "    plt.savefig('prior_predictive_measurements_model2.png')\n",
    "    plt.show()"
   ],
   "id": "cc97413a90d408ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Prepare Stan data\n",
    "stan_data = {\n",
    "    'N': len(X_train_transformed),\n",
    "    'K': len(feature_names),\n",
    "    'K_dow': len(dow_indices),\n",
    "    'dow_indices': [i+1 for i in dow_indices],  # Stan uses 1-based indexing\n",
    "    'X': X_train_transformed,\n",
    "    'y': y_train.values,\n",
    "    'N_new': len(X_test_transformed) if len(X_test) > 0 else 0,\n",
    "    'X_new': X_test_transformed if len(X_test) > 0 else np.zeros((0, len(feature_names)))\n",
    "}"
   ],
   "id": "f674d6b47171b002"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define Stan model with log-likelihood for arviz\n",
    "stan_code = \"\"\"\n",
    "data {\n",
    "  int<lower=0> N;          // Number of training samples\n",
    "  int<lower=0> K;          // Number of features\n",
    "  int<lower=0> K_dow;      // Number of day_of_week features\n",
    "  array[K_dow] int<lower=1,upper=K> dow_indices; // Indices of day_of_week features (Corrected syntax)\n",
    "  matrix[N, K] X;          // Feature matrix\n",
    "  vector[N] y;             // Target variable\n",
    "  int<lower=0> N_new;      // Number of test samples\n",
    "  matrix[N_new, K] X_new;  // Test feature matrix\n",
    "}\n",
    "parameters {\n",
    "  real beta0;              // Intercept\n",
    "  vector[K] beta;          // Feature coefficients\n",
    "  real mu_dow;             // Mean of day_of_week coefficients\n",
    "  real<lower=0> sigma_dow; // SD of day_of_week coefficients\n",
    "  real<lower=0> sigma;     // Noise SD\n",
    "}\n",
    "model {\n",
    "  vector[N] mu;\n",
    "  // Priors\n",
    "  beta0 ~ normal(0, 5);\n",
    "\n",
    "  // Default prior for most beta coefficients\n",
    "  for (k in 1:K) {\n",
    "    beta[k] ~ normal(0, 5);\n",
    "  }\n",
    "\n",
    "  // Hierarchical prior for day_of_week coefficients\n",
    "  for (i in 1:K_dow) {\n",
    "    beta[dow_indices[i]] ~ normal(mu_dow, sigma_dow);\n",
    "  }\n",
    "\n",
    "  mu_dow ~ normal(0, 2);\n",
    "  sigma_dow ~ cauchy(0, 1);\n",
    "  sigma ~ cauchy(0, 2.5);\n",
    "\n",
    "  // Likelihood\n",
    "  for (n in 1:N) {\n",
    "    mu[n] = beta0 + dot_product(X[n], beta);\n",
    "  }\n",
    "  y ~ normal(mu, sigma);\n",
    "}\n",
    "generated quantities {\n",
    "  vector[N_new] y_pred;\n",
    "  vector[N] log_lik;\n",
    "  for (n in 1:N_new) {\n",
    "    y_pred[n] = normal_rng(dot_product(X_new[n], beta) + beta0, sigma);\n",
    "  }\n",
    "  for (n in 1:N) {\n",
    "    log_lik[n] = normal_lpdf(y[n] | dot_product(X[n], beta) + beta0, sigma);\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Save Stan model\n",
    "with open('hierarchical_regression.stan', 'w') as f:\n",
    "    f.write(stan_code)"
   ],
   "id": "20313f08514f50e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Compile and fit model\n",
    "model = CmdStanModel(stan_file='hierarchical_regression.stan')\n",
    "fit = model.sample(data=stan_data, chains=4, iter_sampling=2000, iter_warmup=500, adapt_delta=0.9 ,seed=42)"
   ],
   "id": "a67b9c3825b043fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Check sampling diagnostics\n",
    "summary = fit.summary()\n",
    "rhat = summary['R_hat'].max() if 'R_hat' in summary.columns else float('nan')\n",
    "# Try 'n_eff' as the column name, fallback to None if missing\n",
    "n_eff = summary['n_eff'].min() if 'n_eff' in summary.columns else None\n",
    "print(f\"Sampling Diagnostics: Max R-hat = {rhat:.4f}, Min N_Eff = {n_eff if n_eff is not None else 'N/A'}\")\n",
    "if rhat > 1.1 or (n_eff is not None and n_eff < 100):\n",
    "    print(\"Warning: Sampling issues detected. Consider increasing iter_sampling or adapt_delta, or check model specification.\")"
   ],
   "id": "7b9ac31831433227"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Posterior predictive analysis\n",
    "if len(X_test_transformed) > 0:\n",
    "    y_pred = fit.stan_variable('y_pred').mean(axis=0)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"Posterior Predictive Metrics (Model 2):\")\n",
    "    print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "    print(f\"RÂ² Score: {r2:.4f}\")\n",
    "    # Check consistency\n",
    "    y_pred_samples = fit.stan_variable('y_pred')\n",
    "    credible_intervals = np.percentile(y_pred_samples, [2.5, 97.5], axis=0)\n",
    "    within_ci = np.mean((y_test >= credible_intervals[0]) & (y_test <= credible_intervals[1]))\n",
    "    print(f\"Proportion of test data within 95% credible intervals: {within_ci:.2f}\")\n",
    "    if within_ci < 0.9:\n",
    "        print(\"Warning: Less than 90% of test data within credible intervals. Consider non-linear effects or additional features.\")"
   ],
   "id": "7b707bd6ac6ed27a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Visualization: Actual vs. Predicted Passenger Counts\n",
    "    if 'date' in test_data.columns:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(test_data['date'], y_test, label='Actual', color='blue')\n",
    "        plt.plot(test_data['date'], y_pred, label='Predicted', color='red', alpha=0.7)\n",
    "        plt.title('Actual vs. Predicted Passenger Counts (Model 2)')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Normalized Passenger Count')\n",
    "        plt.legend()\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('actual_vs_predicted_model2.png')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(y_test.index, y_test, label='Actual', color='blue')\n",
    "        plt.plot(y_test.index, y_pred, label='Predicted', color='red', alpha=0.7)\n",
    "        plt.title('Actual vs. Predicted Passenger Counts (Model 2)')\n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel('Normalized Passenger Count')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('actual_vs_predicted_model2.png')\n",
    "        plt.close()\n",
    "\n",
    "    # Visualization: Residuals Plot\n",
    "    residuals = y_test - y_pred\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.scatter(test_data['date'] if 'date' in test_data.columns else y_test.index, residuals, color='purple', alpha=0.5)\n",
    "    plt.axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "    plt.title('Residuals of Predicted vs. Actual Passenger Counts (Model 2)')\n",
    "    plt.xlabel('Date' if 'date' in test_data.columns else 'Index')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('residuals_model2.png')\n",
    "    plt.close()"
   ],
   "id": "3f9cd9e453bff8d4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Parameter marginal distributions\n",
    "beta_samples = fit.stan_variable('beta')\n",
    "beta0_samples = fit.stan_variable('beta0')\n",
    "sigma_samples = fit.stan_variable('sigma')\n",
    "mu_dow_samples = fit.stan_variable('mu_dow')\n",
    "sigma_dow_samples = fit.stan_variable('sigma_dow')\n",
    "print(\"\\nParameter Summaries (Model 2):\")\n",
    "for i, name in enumerate(feature_names):\n",
    "    mean, std = beta_samples[:, i].mean(), beta_samples[:, i].std()\n",
    "    ci = np.percentile(beta_samples[:, i], [2.5, 97.5])\n",
    "    print(f\"{name}: Mean = {mean:.4f}, SD = {std:.4f}, 95% CI = [{ci[0]:.4f}, {ci[1]:.4f}]\")\n",
    "print(f\"beta0: Mean = {beta0_samples.mean():.4f}, SD = {beta0_samples.std():.4f}, 95% CI = [{np.percentile(beta0_samples, 2.5):.4f}, {np.percentile(beta0_samples, 97.5):.4f}]\")\n",
    "print(f\"mu_dow: Mean = {mu_dow_samples.mean():.4f}, SD = {mu_dow_samples.std():.4f}, 95% CI = [{np.percentile(mu_dow_samples, 2.5):.4f}, {np.percentile(mu_dow_samples, 97.5):.4f}]\")\n",
    "print(f\"sigma_dow: Mean = {sigma_dow_samples.mean():.4f}, SD = {sigma_dow_samples.std():.4f}, 95% CI = [{np.percentile(sigma_dow_samples, 2.5):.4f}, {np.percentile(sigma_dow_samples, 97.5):.4f}]\")\n",
    "print(f\"sigma: Mean = {sigma_samples.mean():.4f}, SD = {sigma_samples.std():.4f}, 95% CI = [{np.percentile(sigma_samples, 2.5):.4f}, {np.percentile(sigma_samples, 97.5):.4f}]\")"
   ],
   "id": "a0685da39d08028a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Plot parameter histograms\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, name in enumerate(feature_names[:4]):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.hist(beta_samples[:, i], bins=30, density=True)\n",
    "    plt.title(f'Posterior: {name} (Model 2)')\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Density')\n",
    "plt.tight_layout()\n",
    "plt.savefig('parameter_histograms_model2.png')\n",
    "plt.show()"
   ],
   "id": "b185f1062a505f52"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Save sampling output to CSV files\n",
    "csv_dir = \"csv_output_model2\"\n",
    "fit.save_csvfiles(dir=csv_dir)"
   ],
   "id": "f7768424841813fc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Compute information criteria with arviz using from_cmdstanpy\n",
    "idata = az.from_cmdstanpy(posterior=fit, log_likelihood='log_lik')\n",
    "waic = az.waic(idata)\n",
    "loo = az.loo(idata)\n",
    "print(f\"\\nInformation Criteria (Model 2):\")\n",
    "print(f\"WAIC: {waic.elpd_waic} (+/- {waic.se})\")\n",
    "print(f\"PSIS-LOO: {loo.elpd_loo} (+/- {loo.se})\")\n",
    "if any(loo.pareto_k > 0.7):\n",
    "    print(\"Warning: High Pareto k values detected. Results may be unreliable.\")"
   ],
   "id": "72d133e178c0673f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
