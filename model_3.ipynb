{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from cmdstanpy import CmdStanModel\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from cmdstanpy import install_cmdstan\n",
    "install_cmdstan()"
   ],
   "id": "172b07316897be1f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load preprocessed data\n",
    "train_data = pd.read_csv('processed_train_data.csv')\n",
    "test_data = pd.read_csv('processed_test_data.csv')\n",
    "\n",
    "# Check if data is empty\n",
    "if len(train_data) == 0:\n",
    "    raise ValueError(\"Train data is empty. Check preprocessing step.\")\n",
    "if len(test_data) == 0:\n",
    "    print(\"Warning: Test data is empty. Predictions will be skipped.\")\n",
    "\n",
    "# Define features (exclude quality flags and season)\n",
    "categorical_cols = ['is_raining', 'day_of_week', 'month']\n",
    "numerical_cols = ['passenger_count_lag1', 'temp_7d_mean', 'max_temp', 'Q_TG',\n",
    "                  'precipitation', 'snow_depth', 'global_radiation', 'pressure',\n",
    "                  'humidity', 'cloud_cover']\n",
    "features = numerical_cols + categorical_cols\n",
    "target = 'passenger_count'"
   ],
   "id": "129fc5b94b63329b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Prepare training and test sets with polynomial and interaction terms\n",
    "X_train = train_data[features].copy()\n",
    "X_test = test_data[features].copy() if len(test_data) > 0 else pd.DataFrame(columns=X_train.columns)\n",
    "y_train = train_data[target]\n",
    "y_test = test_data[target] if len(test_data) > 0 else pd.Series()"
   ],
   "id": "135669485e5fe65d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Add polynomial features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly_features = poly.fit_transform(X_train[numerical_cols])\n",
    "poly_feature_names = poly.get_feature_names_out(numerical_cols)\n",
    "X_train_poly = pd.DataFrame(poly_features, columns=poly_feature_names, index=X_train.index)\n",
    "X_train = pd.concat([X_train.drop(columns=numerical_cols), X_train_poly], axis=1)\n",
    "\n",
    "if len(X_test) > 0:\n",
    "    poly_features_test = poly.transform(X_test[numerical_cols])\n",
    "    X_test_poly = pd.DataFrame(poly_features_test, columns=poly_feature_names, index=X_test.index)\n",
    "    X_test = pd.concat([X_test.drop(columns=numerical_cols), X_test_poly], axis=1)"
   ],
   "id": "5c73895cfe929d56"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Add interaction term (passenger_count_lag1 * day_of_week effect)\n",
    "dow_cols = [col for col in X_train.columns if col.startswith('day_of_week_')]\n",
    "for dow_col in dow_cols:\n",
    "    X_train[f'lag_dow_{dow_col}'] = X_train['passenger_count_lag1'] * X_train[dow_col]\n",
    "    if len(X_test) > 0:\n",
    "        X_test[f'lag_dow_{dow_col}'] = X_test['passenger_count_lag1'] * X_test[dow_col]\n",
    "numerical_cols = list(X_train_poly.columns) + [f'lag_dow_{col}' for col in dow_cols]"
   ],
   "id": "bfa442d58af4f8f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Preprocess categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_cols),\n",
    "        ('num', 'passthrough', numerical_cols)\n",
    "    ])\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test) if len(X_test) > 0 else np.array([])"
   ],
   "id": "1b4b45efdbe8ca19"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Get feature names\n",
    "cat_feature_names = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_cols)\n",
    "feature_names = list(cat_feature_names) + numerical_cols\n",
    "dow_indices = [i for i, name in enumerate(feature_names) if name.startswith('day_of_week_')]"
   ],
   "id": "6543fb10229f77d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Prior predictive checks\n",
    "n_sim = 1000\n",
    "beta0_sim = np.random.normal(0, 5, n_sim)\n",
    "beta_sim = np.random.normal(0, 5, (n_sim, len(feature_names)))\n",
    "mu_dow_sim = np.random.normal(0, 2, n_sim)\n",
    "sigma_dow_sim = np.abs(np.random.standard_cauchy(n_sim))  # Relaxed scale\n",
    "beta_dow_sim = np.array([np.random.normal(mu_dow_sim, 0.25) for _ in range(len(dow_indices))]).T  # Relaxed prior\n",
    "sigma_sim = np.abs(np.random.standard_cauchy(n_sim) * 2.5)\n",
    "print(\"Prior Parameter Checks:\")\n",
    "print(f\"beta0 range: [{beta0_sim.min():.2f}, {beta0_sim.max():.2f}]\")\n",
    "print(f\"beta range: [{beta_sim.min():.2f}, {beta_sim.max():.2f}]\")\n",
    "print(f\"mu_dow range: [{mu_dow_sim.min():.2f}, {mu_dow_sim.max():.2f}]\")\n",
    "print(f\"sigma_dow range: [{sigma_dow_sim.min():.2f}, {sigma_dow_sim.max():.2f}]\")\n",
    "print(f\"beta_dow range: [{beta_dow_sim.min():.2f}, {beta_dow_sim.max():.2f}]\")\n",
    "print(f\"sigma range: [{sigma_sim.min():.2f}, {sigma_sim.max():.2f}]\")"
   ],
   "id": "d46fb7c697785aff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Prior predictive measurements\n",
    "if len(X_train_transformed) > 0:\n",
    "    mu_sim = beta0_sim + X_train_transformed[:n_sim] @ beta_sim.T\n",
    "    y_sim = np.array([np.random.normal(mu_sim[i], sigma_sim[i]) for i in range(n_sim)])\n",
    "    print(f\"Prior Predictive Measurements range: [{y_sim.min():.2f}, {y_sim.max():.2f}]\")\n",
    "    plt.hist(y_sim.flatten(), bins=50, density=True)\n",
    "    plt.title('Prior Predictive Distribution of Passenger Counts (Model 2)')\n",
    "    plt.xlabel('Normalized Passenger Count')\n",
    "    plt.ylabel('Density')\n",
    "    plt.savefig('prior_predictive_measurements_model2.png')\n",
    "    plt.show()"
   ],
   "id": "342807e9720dca82"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Prepare Stan data\n",
    "stan_data = {\n",
    "    'N': len(X_train_transformed),\n",
    "    'K': len(feature_names),\n",
    "    'K_dow': len(dow_indices),\n",
    "    'dow_indices': [i+1 for i in dow_indices],  # Stan uses 1-based indexing\n",
    "    'X': X_train_transformed,\n",
    "    'y': y_train.values,\n",
    "    'N_new': len(X_test_transformed) if len(X_test) > 0 else 0,\n",
    "    'X_new': X_test_transformed if len(X_test) > 0 else np.zeros((0, len(feature_names)))\n",
    "}"
   ],
   "id": "f3e14fb05282808a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define Stan model with relaxed priors\n",
    "stan_code = \"\"\"\n",
    "data {\n",
    "  int<lower=0> N;          // Number of training samples\n",
    "  int<lower=0> K;          // Number of features\n",
    "  int<lower=0> K_dow;      // Number of day_of_week features\n",
    "  array[K_dow] int<lower=1,upper=K> dow_indices; // Indices of day_of_week features - Corrected syntax\n",
    "  matrix[N, K] X;          // Feature matrix\n",
    "  vector[N] y;             // Target variable\n",
    "  int<lower=0> N_new;      // Number of test samples\n",
    "  matrix[N_new, K] X_new;  // Test feature matrix\n",
    "}\n",
    "parameters {\n",
    "  real beta0;              // Intercept\n",
    "  vector[K] beta;          // Feature coefficients\n",
    "  real mu_dow;             // Mean of day_of_week coefficients\n",
    "  real<lower=0> sigma_dow; // SD of day_of_week coefficients\n",
    "  real<lower=0> sigma;     // Noise SD\n",
    "}\n",
    "model {\n",
    "  vector[N] mu;\n",
    "  // Priors\n",
    "  beta0 ~ normal(0, 5);\n",
    "  for (k in 1:K) {\n",
    "    // Note: Stan arrays are 1-indexed, but the loop is 1 to K.\n",
    "    // dow_indices contains 1-based indices from Python's 0-based.\n",
    "    // The 'in' operator works with 1-based indices as expected here.\n",
    "\n",
    "    // Stan does not support 'in' operator directly for this check.\n",
    "    // Use a loop to check if k is in dow_indices\n",
    "    int is_dow = 0; // Flag to check if k is a day_of_week index\n",
    "    for (i in 1:K_dow) {\n",
    "      if (k == dow_indices[i]) {\n",
    "        is_dow = 1;\n",
    "        break; // Exit inner loop once a match is found\n",
    "      }\n",
    "    }\n",
    "\n",
    "    if (is_dow) {\n",
    "      beta[k] ~ normal(mu_dow, 0.25);  // Relaxed prior\n",
    "    } else {\n",
    "      beta[k] ~ normal(0, 5);\n",
    "    }\n",
    "  }\n",
    "  mu_dow ~ normal(0, 2);\n",
    "  sigma_dow ~ cauchy(0, 1);  // Relaxed scale\n",
    "  sigma ~ cauchy(0, 2.5);\n",
    "\n",
    "  // Likelihood\n",
    "  for (n in 1:N) {\n",
    "    mu[n] = beta0 + dot_product(X[n], beta);\n",
    "  }\n",
    "  y ~ normal(mu, sigma);\n",
    "}\n",
    "generated quantities {\n",
    "  vector[N_new] y_pred;\n",
    "  for (n in 1:N_new) {\n",
    "    y_pred[n] = normal_rng(dot_product(X_new[n], beta) + beta0, sigma);\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Save Stan model\n",
    "with open('hierarchical_regression_improved.stan', 'w') as f:\n",
    "    f.write(stan_code)"
   ],
   "id": "93d4d5773a79096a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Compile and fit model with optimized sampling\n",
    "model = CmdStanModel(stan_file='hierarchical_regression_improved.stan')\n",
    "fit = model.sample(data=stan_data, chains=4, iter_sampling=2000, iter_warmup=500, adapt_delta=0.9, max_treedepth=8, seed=42)"
   ],
   "id": "89fe6554362b69a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Check sampling diagnostics\n",
    "summary = fit.summary()\n",
    "rhat = summary['R_hat'].max() if 'R_hat' in summary.columns else float('nan')\n",
    "n_eff = summary['n_eff'].min() if 'n_eff' in summary.columns else None\n",
    "print(f\"Sampling Diagnostics: Max R-hat = {rhat:.4f}, Min N_Eff = {n_eff if n_eff is not None else 'N/A'}\")\n",
    "if rhat > 1.1 or (n_eff is not None and n_eff < 100):\n",
    "    print(\"Warning: Sampling issues detected. Consider further increasing iter_sampling or adapt_delta.\")"
   ],
   "id": "4e78b5100902e55f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Posterior predictive analysis\n",
    "if len(X_test_transformed) > 0:\n",
    "    y_pred = fit.stan_variable('y_pred').mean(axis=0)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"Posterior Predictive Metrics (Model 2 - Optimized):\")\n",
    "    print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "    print(f\"R² Score: {r2:.4f}\")\n",
    "    # Check consistency\n",
    "    y_pred_samples = fit.stan_variable('y_pred')\n",
    "    credible_intervals = np.percentile(y_pred_samples, [2.5, 97.5], axis=0)\n",
    "    within_ci = np.mean((y_test >= credible_intervals[0]) & (y_test <= credible_intervals[1]))\n",
    "    print(f\"Proportion of test data within 95% credible intervals: {within_ci:.2f}\")\n",
    "    if within_ci < 0.9:\n",
    "        print(\"Warning: Less than 90% of test data within credible intervals. Consider non-linear effects or additional features.\")"
   ],
   "id": "3d5f96e419196187"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Parameter marginal distributions\n",
    "beta_samples = fit.stan_variable('beta')\n",
    "beta0_samples = fit.stan_variable('beta0')\n",
    "sigma_samples = fit.stan_variable('sigma')\n",
    "mu_dow_samples = fit.stan_variable('mu_dow')\n",
    "sigma_dow_samples = fit.stan_variable('sigma_dow')\n",
    "print(\"\\nParameter Summaries (Model 2 - Optimized):\")\n",
    "for i, name in enumerate(feature_names):\n",
    "    mean, std = beta_samples[:, i].mean(), beta_samples[:, i].std()\n",
    "    ci = np.percentile(beta_samples[:, i], [2.5, 97.5])\n",
    "    print(f\"{name}: Mean = {mean:.4f}, SD = {std:.4f}, 95% CI = [{ci[0]:.4f}, {ci[1]:.4f}]\")\n",
    "print(f\"beta0: Mean = {beta0_samples.mean():.4f}, SD = {beta0_samples.std():.4f}, 95% CI = [{np.percentile(beta0_samples, 2.5):.4f}, {np.percentile(beta0_samples, 97.5):.4f}]\")\n",
    "print(f\"mu_dow: Mean = {mu_dow_samples.mean():.4f}, SD = {mu_dow_samples.std():.4f}, 95% CI = [{np.percentile(mu_dow_samples, 2.5):.4f}, {np.percentile(mu_dow_samples, 97.5):.4f}]\")\n",
    "print(f\"sigma_dow: Mean = {sigma_dow_samples.mean():.4f}, SD = {sigma_dow_samples.std():.4f}, 95% CI = [{np.percentile(sigma_dow_samples, 2.5):.4f}, {np.percentile(sigma_dow_samples, 97.5):.4f}]\")\n",
    "print(f\"sigma: Mean = {sigma_samples.mean():.4f}, SD = {sigma_samples.std():.4f}, 95% CI = [{np.percentile(sigma_samples, 2.5):.4f}, {np.percentile(sigma_samples, 97.5):.4f}]\")"
   ],
   "id": "d312b71cc1fbc713"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Visualization: Actual vs. Predicted\n",
    "if len(test_data) > 0 and 'date' in test_data.columns:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(test_data['date'], y_test, label='Actual', color='blue')\n",
    "    plt.plot(test_data['date'], y_pred, label='Predicted', color='red', alpha=0.7)\n",
    "    plt.title('Actual vs. Predicted Passenger Counts (Model 2 - Optimized)')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Normalized Passenger Count')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('actual_vs_predicted_model2.png')\n",
    "    plt.show()\n",
    "    print(\"Visualization saved as 'actual_vs_predicted_model2.png'\")"
   ],
   "id": "7ec83cc8062013e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Save predictions\n",
    "if len(test_data) > 0:\n",
    "    test_data['predicted_passenger_count'] = y_pred\n",
    "    test_data.to_csv('predictions_2023_model2_optimized.csv', index=False)\n",
    "    print(\"Predictions saved as 'predictions_2023_model2_optimized.csv'\")"
   ],
   "id": "ccba8574c22414f8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
